# LLM Configuration (vLLM)
LLM_PROVIDER=vllm
VLLM_MODEL=Qwen/Qwen2.5-0.5B-Instruct
VLLM_HOST=localhost
VLLM_PORT=8000
VLLM_MAX_MODEL_LEN=8192
# VLLM_API_KEY=  # Optional, if authentication is enabled

# Hugging Face Configuration
HUGGING_FACE_HUB_TOKEN=your_api_key_here

# GPU Configuration
CUDA_VISIBLE_DEVICES=0
VLLM_GPU_MEMORY_UTILIZATION=0.65
VLLM_TENSOR_PARALLEL_SIZE=1

# Model Recommendations:
# Standard models (recommended):
# VLLM_MODEL=Qwen/Qwen2.5-7B-Instruct
# VLLM_MODEL=meta-llama/Llama-3.1-8B-Instruct
# VLLM_MODEL=mistralai/Mistral-7B-Instruct-v0.3

# Smaller efficient models:
# VLLM_MODEL=Qwen/Qwen2.5-3B-Instruct

# Embedding Models (sentence-transformers)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# Alternative embedding models:
# EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2
# EMBEDDING_MODEL=BAAI/bge-small-en-v1.5

# Reranker Model (still using sentence-transformers)
RERANKER_MODEL=BAAI/bge-reranker-base

# Database Configuration (PostgreSQL with pgvector)
DB_HOST=localhost
DB_PORT=5432
DB_NAME=citetube
DB_USER=postgres
DB_PASSWORD=12345

# Search Configuration
USE_RERANKER=true
TOP_K=8
VECTOR_TOP_K=30
BM25_TOP_K=30

# LLM Generation Settings
TEMPERATURE=0.1
MAX_TOKENS=1024

# Optional: Alternative LLM Providers (if you want to use APIs instead)
# LLM_PROVIDER=openai
# OPENAI_API_KEY=your_api_key_here
# OPENAI_MODEL=gpt-4

# LLM_PROVIDER=anthropic
# ANTHROPIC_API_KEY=your_api_key_here
# ANTHROPIC_MODEL=claude-3-sonnet-20240229